#!/usr/bin/env python3
import os
import struct
import argparse

# NatriumFS v1 constants
BLOCK_SIZE = 1024                 # 2 * 512
ROOT_DIR_BLOCKS = 4               # root directory uses blocks 2-5 (4 blocks)
MAX_DIR_BLOCKS_TO_READ = 8        # safe cap when reading directories
ROOT_DIR_MAX_ENTRIES = 127         # max entries in root dir
ATTR_FILE = 0x00
ATTR_DIR = 0x80
SUPERBLOCK_NEXT_BLOCK_OFFSET = 17  # offset of next free block word in superblock

# Directory entry offsets
OFF_NAME = 0
OFF_START = 16
OFF_NUM_BLOCKS = 18
OFF_ATTR = 19
OFF_PADDING = 20

class NatriumFS:
    def __init__(self, path):
        self.path = path
        self.disk = None

    def open(self, mode='r+b'):
        if not os.path.exists(self.path) and 'w' not in mode:
            raise FileNotFoundError(self.path)
        self.disk = open(self.path, mode)

    def close(self):
        if self.disk:
            self.disk.flush()
            self.disk.close()
            self.disk = None

    # ---- Superblock helpers ----
    def _read_next_free_block(self):
        self.disk.seek(BLOCK_SIZE + SUPERBLOCK_NEXT_BLOCK_OFFSET)
        return struct.unpack('<H', self.disk.read(2))[0]

    def _write_next_free_block(self, block_num):
        self.disk.seek(BLOCK_SIZE + SUPERBLOCK_NEXT_BLOCK_OFFSET)
        self.disk.write(struct.pack('<H', block_num))

    # ---- Disk creation ----
    def create(self, size_kb, volume_name="NATRIUM"):
        total_bytes = size_kb * 1024
        with open(self.path, "wb") as f:
            # Boot block
            f.write(b'\x00' * BLOCK_SIZE)

            # Superblock
            name = volume_name.ljust(16).encode('ascii')[:16]
            f.write(name)
            f.write(b'\x01')                  # FS version
            f.write(struct.pack('<H', 6))     # next free block = 6
            f.write(b'\x00' * (BLOCK_SIZE - 19))

            # Root directory
            f.write(bytes([ROOT_DIR_MAX_ENTRIES]))
            f.write(b'\x00' * 31)
            f.write(b'\x00' * (BLOCK_SIZE * ROOT_DIR_BLOCKS - 32))

            # Fill remaining disk
            remaining = total_bytes - f.tell()
            if remaining < 0:
                raise ValueError("Disk size too small for filesystem structures")
            f.write(b'\x00' * remaining)

    # ---- Low-level block IO ----
    def _read_block(self, block_num, size=BLOCK_SIZE):
        self.disk.seek(block_num * BLOCK_SIZE)
        return self.disk.read(size)

    def _write_block(self, block_num, data):
        if len(data) > BLOCK_SIZE:
            raise ValueError("Data exceeds block size")
        self.disk.seek(block_num * BLOCK_SIZE)
        self.disk.write(data.ljust(BLOCK_SIZE, b'\x00'))

    # ---- Directory helpers ----
    def _read_dir_buffer(self, start_block, num_blocks):
        read_blocks = min(num_blocks, MAX_DIR_BLOCKS_TO_READ)
        return self._read_block(start_block, read_blocks * BLOCK_SIZE)

    def _write_dir_buffer(self, start_block, buf, blocks=ROOT_DIR_BLOCKS):
        for i in range(blocks):
            chunk = buf[i * BLOCK_SIZE:(i + 1) * BLOCK_SIZE]
            self._write_block(start_block + i, chunk)

    def _parse_dir_buffer(self, buf):
        entries = []
        for i in range(ROOT_DIR_MAX_ENTRIES):
            offset = 32 + i * 32
            if offset + 32 > len(buf):
                break
            entry = buf[offset:offset + 32]
            if entry[0] == 0:
                continue
            name = entry[OFF_NAME:OFF_NAME + 16].decode('ascii', errors='ignore').rstrip()
            start_block, = struct.unpack('<H', entry[OFF_START:OFF_START + 2])
            num_blocks = entry[OFF_NUM_BLOCKS]
            attr = entry[OFF_ATTR]
            padding = struct.unpack('<H', entry[OFF_PADDING:OFF_PADDING + 2])[0]
            entries.append({
                "name": name,
                "start_block": start_block,
                "num_blocks": num_blocks,
                "attr": attr,
                "padding": padding
            })
        return entries

    def list_dir(self, start_block=2):
        buf = self._read_block(start_block, BLOCK_SIZE * ROOT_DIR_BLOCKS)
        return self._parse_dir_buffer(buf)

    def find_dir_by_name(self, name):
        for e in self.list_dir(2):
            if e['name'] == name and (e['attr'] & ATTR_DIR):
                return e['start_block']
        return None

    # ---- Directory creation ----
    def mkdir(self, name):
        root_buf = bytearray(self._read_block(2, BLOCK_SIZE * ROOT_DIR_BLOCKS))
        offset = None
        for i in range(ROOT_DIR_MAX_ENTRIES):
            off = 32 + i * 32
            if root_buf[off] == 0:
                offset = off
                break
        if offset is None:
            raise RuntimeError("No free directory entries in root")

        # allocate using next_free_block
        start_block = self._read_next_free_block()
        self._write_next_free_block(start_block + ROOT_DIR_BLOCKS)

        # initialize empty directory buffer
        empty_dir = bytes([ROOT_DIR_MAX_ENTRIES]) + b'\x00' * 31
        empty_dir += b'\x00' * (BLOCK_SIZE * ROOT_DIR_BLOCKS - 32)
        for i in range(ROOT_DIR_BLOCKS):
            self._write_block(start_block + i, empty_dir[i * BLOCK_SIZE:(i + 1) * BLOCK_SIZE])

        # write directory entry
        entry = bytearray(32)
        entry[OFF_NAME:OFF_NAME + 16] = name.ljust(16).encode('ascii')[:16]
        entry[OFF_START:OFF_START + 2] = struct.pack('<H', start_block)
        entry[OFF_NUM_BLOCKS] = ROOT_DIR_BLOCKS
        entry[OFF_ATTR] = ATTR_DIR
        entry[OFF_PADDING:OFF_PADDING + 2] = struct.pack('<H', 0)
        entry[22:32] = b'\x00' * 10

        root_buf[offset:offset + 32] = bytes(entry)
        self._write_dir_buffer(2, root_buf)
        return start_block

    # ---- File allocation ----
    def add_file(self, file_path, target_name=None, parent_block=2):
        if target_name is None:
            target_name = os.path.basename(file_path)
        with open(file_path, 'rb') as f:
            data = f.read()
        file_size = len(data)
        num_blocks = (file_size + BLOCK_SIZE - 1) // BLOCK_SIZE
        if num_blocks == 0:
            num_blocks = 1

        parent_buf = bytearray(self._read_block(parent_block, BLOCK_SIZE * ROOT_DIR_BLOCKS))
        entry_offset = None
        for i in range(ROOT_DIR_MAX_ENTRIES):
            off = 32 + i * 32
            if parent_buf[off] == 0:
                entry_offset = off
                break
        if entry_offset is None:
            raise RuntimeError("No free directory entries in target directory")

        # allocate using next_free_block
        start_block = self._read_next_free_block()
        self._write_next_free_block(start_block + num_blocks)

        # write file data
        for i in range(num_blocks):
            chunk = data[i * BLOCK_SIZE:(i + 1) * BLOCK_SIZE]
            self._write_block(start_block + i, chunk)

        # compute padding
        padding = (num_blocks * BLOCK_SIZE) - file_size
        if padding < 0:
            padding = 0
        if padding >= BLOCK_SIZE:
            padding = BLOCK_SIZE - 1

        # write directory entry
        entry = bytearray(32)
        entry[OFF_NAME:OFF_NAME + 16] = target_name.ljust(16).encode('ascii')[:16]
        entry[OFF_START:OFF_START + 2] = struct.pack('<H', start_block)
        entry[OFF_NUM_BLOCKS] = num_blocks
        entry[OFF_ATTR] = ATTR_FILE
        entry[OFF_PADDING:OFF_PADDING + 2] = struct.pack('<H', padding)
        entry[22:32] = b'\x00' * 10

        parent_buf[entry_offset:entry_offset + 32] = bytes(entry)
        self._write_dir_buffer(parent_block, parent_buf)
        return start_block

    # ---- File reading ----
    def read_file(self, file_name, out_path=None, parent_block=2):
        buf = self._read_block(parent_block, BLOCK_SIZE * ROOT_DIR_BLOCKS)
        entries = self._parse_dir_buffer(buf)
        for e in entries:
            if e['name'] == file_name and (e['attr'] & ATTR_DIR) == 0:
                data = bytearray()
                for i in range(e['num_blocks']):
                    data.extend(self._read_block(e['start_block'] + i))
                padding = int(e.get('padding', 0) or 0)
                padding = max(0, min(padding, BLOCK_SIZE - 1, len(data)))
                total_bytes = e['num_blocks'] * BLOCK_SIZE - padding
                data = bytes(data[:total_bytes])
                if out_path:
                    os.makedirs(os.path.dirname(out_path), exist_ok=True)
                    with open(out_path, 'wb') as f:
                        f.write(data)
                return data
        raise FileNotFoundError(file_name)

    # ---- Directory extraction ----
    def extract_all(self, output_dir, parent_block=2, rel_path=""):
        target_dir = os.path.join(output_dir, rel_path)
        os.makedirs(target_dir, exist_ok=True)

        dir_buf = self._read_block(parent_block, BLOCK_SIZE * ROOT_DIR_BLOCKS)
        entries = self._parse_dir_buffer(dir_buf)

        for e in entries:
            if e['attr'] & ATTR_DIR:
                sub_rel = os.path.join(rel_path, e['name'])
                read_blocks = min(e['num_blocks'], MAX_DIR_BLOCKS_TO_READ)
                self._extract_dir_to_host(output_dir, e['start_block'], sub_rel, read_blocks)
            else:
                self._write_file_and_decode(e, output_dir, rel_path)

    def _extract_dir_to_host(self, output_dir, dir_start_block, rel_path, read_blocks):
        target_dir = os.path.join(output_dir, rel_path)
        os.makedirs(target_dir, exist_ok=True)
        buf = self._read_block(dir_start_block, BLOCK_SIZE * read_blocks)
        entries = self._parse_dir_buffer(buf)
        for e in entries:
            if e['attr'] & ATTR_DIR:
                print(f"[SKIP-DEEP] {os.path.join(rel_path, e['name'])} (nested dirs not supported)")
                continue
            self._write_file_and_decode(e, output_dir, rel_path)

    def _write_file_and_decode(self, e, output_dir, rel_path):
        out_path = os.path.join(output_dir, rel_path, e['name'])
        data = b''.join(self._read_block(e['start_block'] + i) for i in range(e['num_blocks']))
        total_bytes = e['num_blocks'] * BLOCK_SIZE - e.get('padding', 0)
        data = data[:total_bytes]
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        with open(out_path, 'wb') as f:
            f.write(data)
        print(f"[FILE] {os.path.join(rel_path, e['name'])} ({len(data)} bytes)")

        if e['name'].lower().endswith(".txt"):
            try:
                decoded_text = data.decode('cp437')
                decoded_path = os.path.join(output_dir, rel_path, f"{e['name']}.decoded.txt")
                with open(decoded_path, 'w', encoding='utf-8') as df:
                    df.write(decoded_text)
                print(f"[DECODED] {decoded_path}")
            except Exception as ex:
                print(f"[DECODE-ERROR] {e['name']}: {ex}")

# ---- CLI ----
def main():
    parser = argparse.ArgumentParser(description="NatriumFS v1 utility")
    parser.add_argument("disk", help="Path to NatriumFS disk image")
    subparsers = parser.add_subparsers(dest="command", required=True)

    create = subparsers.add_parser("create", help="Create a new NatriumFS disk image")
    create.add_argument("size_kb", type=int, help="Disk size in KB")
    create.add_argument("--volume", default="NATRIUM", help="Volume name")

    add = subparsers.add_parser("add", help="Add file to disk")
    add.add_argument("file", help="Host file to add")
    add.add_argument("--name", help="Target filename on disk")
    add.add_argument("--dir", help="Target subdirectory name (optional)")

    mkdir_cmd = subparsers.add_parser("mkdir", help="Create a subdirectory in root")
    mkdir_cmd.add_argument("name", help="Subdirectory name")

    list_cmd = subparsers.add_parser("list", help="List files in root or subdirectory")
    list_cmd.add_argument("--dir", help="Subdirectory to list (optional)")

    read_cmd = subparsers.add_parser("read", help="Read a file from disk")
    read_cmd.add_argument("file", help="Filename on disk")
    read_cmd.add_argument("--out", help="Output path on host (optional)")
    read_cmd.add_argument("--dir", help="Subdirectory to read from (optional)")

    extractall = subparsers.add_parser("extractall", help="Extract entire disk to host")
    extractall.add_argument("outdir", help="Destination directory on host")

    args = parser.parse_args()

    fs = NatriumFS(args.disk)

    if args.command == "create":
        fs.create(args.size_kb, args.volume)
        print(f"Created NatriumFS {args.size_kb}KB disk: {args.disk}")
        return

    fs.open('r+b')
    try:
        if args.command == "mkdir":
            block = fs.mkdir(args.name)
            print(f"Created subdirectory '{args.name}' at block {block}")

        elif args.command == "add":
            parent_block = 2
            if args.dir:
                block = fs.find_dir_by_name(args.dir)
                if not block:
                    raise FileNotFoundError(f"Subdirectory '{args.dir}' not found")
                parent_block = block
            start = fs.add_file(args.file, args.name, parent_block)
            print(f"Added '{args.file}' as '{args.name or os.path.basename(args.file)}' at block {start}")

        elif args.command == "list":
            parent_block = 2
            if args.dir:
                block = fs.find_dir_by_name(args.dir)
                if not block:
                    raise FileNotFoundError(f"Subdirectory '{args.dir}' not found")
                parent_block = block
            entries = fs.list_dir(parent_block)
            for e in entries:
                type_str = "DIR" if (e['attr'] & ATTR_DIR) else "FILE"
                print(f"{e['name']:16} {type_str} blocks={e['num_blocks']} start={e['start_block']} pad={e.get('padding',0)}")

        elif args.command == "read":
            parent_block = 2
            if args.dir:
                block = fs.find_dir_by_name(args.dir)
                if not block:
                    raise FileNotFoundError(f"Subdirectory '{args.dir}' not found")
                parent_block = block
            data = fs.read_file(args.file, args.out, parent_block=parent_block)
            if not args.out:
                print(f"Read {len(data)} bytes from '{args.file}'")

        elif args.command == "extractall":
            fs.extract_all(args.outdir)
            print(f"Extracted entire disk to '{args.outdir}'")

    finally:
        fs.close()

if __name__ == "__main__":
    main()
